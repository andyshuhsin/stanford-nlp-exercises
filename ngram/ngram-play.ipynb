{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 0.0305\n",
      "and: 0.0296\n",
      "i: 0.0223\n",
      "to: 0.0209\n",
      "of: 0.0201\n",
      "a: 0.0159\n",
      "you: 0.0143\n",
      "my: 0.0138\n",
      "that: 0.0121\n",
      "in: 0.012\n",
      "is: 0.0105\n",
      "not: 0.0093\n",
      "for: 0.0091\n",
      "with: 0.0088\n",
      "it: 0.008\n",
      "be: 0.0077\n",
      "me: 0.0076\n",
      "your: 0.0076\n",
      "his: 0.0076\n",
      "this: 0.007\n"
     ]
    }
   ],
   "source": [
    "# Helper functions\n",
    "\n",
    "def head_dict(d, n = 20, digits = 4):\n",
    "    for key in sorted(d, key=d.get, reverse=True)[0:n]:\n",
    "        print(\"%s: %s\" % (key, round(d[key], digits)))\n",
    "\n",
    "def normalize_frequencies(d):\n",
    "    total = 0\n",
    "    for key in d:\n",
    "        total += d[key]\n",
    "    for key in d:\n",
    "        d[key] /= total_word_count\n",
    "    return d\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "text = open('shakespeare.txt').read()\n",
    "words = text.lower().replace(',', ' ').replace('.', ' ').split()\n",
    "\n",
    "# Unigram\n",
    "total_word_count = len(words)\n",
    "word_frequencies = Counter(words)\n",
    "\n",
    "unigram = normalize_frequencies(word_frequencies)\n",
    "\n",
    "head_dict(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 'am'): 0.002\n",
      "('of', 'the'): 0.0019\n",
      "('in', 'the'): 0.0018\n",
      "('i', 'have'): 0.0018\n",
      "('i', 'will'): 0.0017\n",
      "('to', 'the'): 0.0015\n",
      "('my', 'lord'): 0.0015\n",
      "('it', 'is'): 0.0011\n",
      "('to', 'be'): 0.0011\n",
      "('that', 'i'): 0.001\n",
      "('and', 'the'): 0.0009\n",
      "('i', 'do'): 0.0009\n",
      "('and', 'i'): 0.0008\n",
      "('of', 'my'): 0.0008\n",
      "('you', 'are'): 0.0007\n",
      "('is', 'the'): 0.0007\n",
      "('i', 'would'): 0.0007\n",
      "('the', 'king'): 0.0007\n",
      "('you', 'have'): 0.0007\n",
      "('he', 'is'): 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Bigram\n",
    "\n",
    "bigram = {}\n",
    "\n",
    "for i in range(0, len(words) - 1):\n",
    "    key = (words[i], words[i+1])\n",
    "    try:\n",
    "        bigram[key] += 1\n",
    "    except KeyError:\n",
    "        bigram[key] = 1\n",
    "normalize_frequencies(bigram)\n",
    "head_dict(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('so', 'long', 'as'): 0.0003\n",
      "('works', 'of', 'william'): 0.0002\n",
      "('of', 'william', 'shakespeare'): 0.0002\n",
      "('complete', 'works', 'of'): 0.0002\n",
      "('world', 'library', 'inc'): 0.0002\n",
      "('the', 'complete', 'works'): 0.0002\n",
      "('of', 'the', 'complete'): 0.0002\n",
      "('by', 'project', 'gutenberg'): 0.0002\n",
      "('service', 'that', 'charges'): 0.0002\n",
      "('machine', 'readable', 'copies'): 0.0002\n",
      "('any', 'service', 'that'): 0.0002\n",
      "('use', 'only', 'and'): 0.0002\n",
      "('library', 'inc', 'and'): 0.0002\n",
      "('and', '(2)', 'are'): 0.0002\n",
      "('includes', 'by', 'any'): 0.0002\n",
      "('such', 'copies', '(1)'): 0.0002\n",
      "('shakespeare', 'is', 'copyright'): 0.0002\n",
      "('project', 'gutenberg', 'etext'): 0.0002\n",
      "('copyright', '1990-1993', 'by'): 0.0002\n",
      "('as', 'such', 'copies'): 0.0002\n"
     ]
    }
   ],
   "source": [
    "# Trigram\n",
    "\n",
    "trigram = {}\n",
    "\n",
    "for i in range(0, len(words) - 2):\n",
    "    key = (words[i], words[i+1], words[i+2])\n",
    "    try:\n",
    "        trigram[key] += 1\n",
    "    except KeyError:\n",
    "        trigram[key] = 1\n",
    "normalize_frequencies(trigram)\n",
    "head_dict(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('if', 'you', 'are', 'not', 'to', 'the', 'king', 'henry', 'the', 'king', 'henry')\n",
      "('if', 'you', 'will', 'not', 'be', 'so', 'bold', 'to', 'say', 'the', 'truth', 'of')\n",
      "('king', 'henry', 'the', 'king', 'henry', 'the', 'king', 'henry', 'the', 'king', 'henry')\n",
      "('king', 'henry', 'the', 'fifth', 'who', 'made', 'thee', 'faint', 'and', 'fly', 'like', 'chidden')\n"
     ]
    }
   ],
   "source": [
    "def shannon_ngram(words, ngram, length=10):\n",
    "    if length == 0:\n",
    "        return words\n",
    "    \n",
    "    n = len(list(ngram.keys())[0])\n",
    "    next_word = ''\n",
    "    max_p = 0\n",
    "    \n",
    "    for key in ngram:\n",
    "        if words[-n+1:] == key[:n-1] and ngram[key] > max_p:\n",
    "            next_word = key[-1]\n",
    "            max_p = ngram[key]\n",
    "            \n",
    "    return shannon_ngram(words + (next_word,), ngram, length - 1)\n",
    "\n",
    "print(shannon_ngram(('if',), bigram))\n",
    "print(shannon_ngram(('if', 'you'), trigram))\n",
    "\n",
    "print(shannon_ngram(('king',), bigram))\n",
    "print(shannon_ngram(('king', 'henry'), trigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6377359784549723e-08\n"
     ]
    }
   ],
   "source": [
    "# Language model\n",
    "\n",
    "train_data = words[0:round(len(words) * 0.8)]\n",
    "validation_data = words[round(len(words) * 0.8)+1:]\n",
    "\n",
    "\n",
    "def get_prob_func(frequency_table):\n",
    "    n = len(list(frequency_table.keys())[0])\n",
    "    assert n >= 2 # Doesn't work with unigrams\n",
    "    \n",
    "    def prob(words, conditional_words):\n",
    "        if len(words) == n and len(conditional_words) == 0:\n",
    "            total_count = 0\n",
    "            target_count = 0\n",
    "            for key in frequency_table:\n",
    "                freq = frequency_table[key]\n",
    "                if key == words:\n",
    "                    target_count = freq\n",
    "                total_count += freq\n",
    "            return target_count / total_count\n",
    "        \n",
    "        elif len(words) == 1 and len(conditional_words) == n - 1:\n",
    "            marginal_count = 0\n",
    "            target_count= 0\n",
    "            for key in frequency_table:\n",
    "                if key[:n-1] == conditional_words:\n",
    "                    marginal_count += frequency_table[key]\n",
    "                    if key[-1] == words[0]:\n",
    "                        target_count += frequency_table[key]\n",
    "            return target_count / marginal_count\n",
    "                    \n",
    "        else:\n",
    "            p = prob((words[-1],), words[-n:-1]) * prob(words[:-1], ())\n",
    "            return p\n",
    "    \n",
    "    return prob\n",
    "\n",
    "\n",
    "def get_trigram_language_model(words):\n",
    "    trigram_table = {}\n",
    "    for i in range(0, len(words) - 2):\n",
    "        key = (words[i], words[i+1], words[i+2])\n",
    "        try:\n",
    "            trigram_table[key] += 1\n",
    "        except KeyError:\n",
    "            trigram_table[key] = 1\n",
    "\n",
    "    prob = get_prob_func(trigram_table)\n",
    "    \n",
    "    def lm(sentence):\n",
    "        return prob(sentence, ())\n",
    "    \n",
    "    return lm\n",
    "\n",
    "lm = get_trigram_language_model(train_data)\n",
    "\n",
    "print(lm(('consider', 'every', 'thing', 'that', 'grows')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perplexity\n",
    "\n",
    "def get_perplexity_func(language_model):\n",
    "    \n",
    "    def perplexity(sentence):\n",
    "        N = len(sentence)\n",
    "        return language_model(sentence) ** (-1 / N)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "perp = get_perplexity_func(lm)\n",
    "print(perp(tuple(words[:100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Smoothing\n",
    "trigram_freq = {}\n",
    "\n",
    "for i in range(0, len(words) - 2):\n",
    "    key1 = (words[i], words[i+1])\n",
    "    key2 = words[i+2]\n",
    "    try:\n",
    "        trigram_freq[key1][key2] += 1\n",
    "    except KeyError:\n",
    "        try: \n",
    "            trigram_freq[key1][key2] = 1\n",
    "        except KeyError:\n",
    "            trigram_freq[key1] = {}\n",
    "            trigram_freq[key1][key2] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Laplace\n",
    "from copy import deepcopy\n",
    "\n",
    "vocabulary = list(set(words))\n",
    "\n",
    "trigram_freq_laplace = deepcopy(trigram_freq)\n",
    "\n",
    "for word1 in vocabulary:\n",
    "    for word2 in vocabulary:\n",
    "        for word3 in vocabulary:\n",
    "            key1 = (word1, word2)\n",
    "            key2 = word3\n",
    "            try:\n",
    "                trigram_freq[key1][key2] += 1\n",
    "            except KeyError:\n",
    "                try: \n",
    "                    trigram_freq[key1][key2] = 1\n",
    "                except KeyError:\n",
    "                    trigram_freq[key1] = {}\n",
    "                    trigram_freq[key1][key2] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(trigram_freq.keys()[0:10])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
